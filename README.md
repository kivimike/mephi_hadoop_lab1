# mephi_hadoop_lab1
Задание
Программа должна вычислять количество сообщений различной значимости (справочник обозначений: 7 – debug, 6 – info, 5 – notice, 4 - warning, warn, 3 - err, error, 2 - crit, 1 - alert,  0 - emerg, panic) в syslog Linux с почасовой гранулярностью.
Output Format:  
	SequenceFile со Snappy сжатием (плюс команда просмотра содержимого 	сжатого файла).
Дополнительные требования:
       Использование Счетчиков. Приложить скриншот использования Счетчиков.
____________________________________________________________________
Комплект поставки: программа для работы с hadoop, написанная на java (lab1_133), python скрипт для генерации логов, их загрузки в hdfs, 
запуска lab1_133 и выкачивания результирующего файла      обратно из hdfs в локальную файловую систему  (hadoop_connection.py).

Сценарий развертывания hadoop идентичен показанному в https://www.youtube.com/watch?v=dWjL9u4AKHc&t=1412s
Включение работы hadoop в псевдораспределенном режиме подробно описано в https://hadoop.apache.org/docs/r2.10.1/hadoop-project-dist/hadoop-common/SingleCluster.html в разделе Pseudo-Distributed Operation.

Запуск hadoop:
Поскольку на моем компьютере стоит Ubuntu, версии 21( не LTS), то перед вызовом start-dfs.sh необходимо отформатировать namenode.
hadoop namenode -format
/opt/hadoop-2.10.1/sbin/start-dfs.sh
/opt/hadoop-2.10.1/sbin/start-yarn.sh

Сценарий использования в том случае, если файлы с логами уже имеются (Пример логов в нужном формате: 5,Jul 27 08:33:39,root,pycharm:,starts):

После успешного запуска можно создать директории пользователей.
hdfs dfs -mkdir /user
hdfs dfs -mkdir /user/{username}

Файлы с логами должны лежать в папке input внутри проекта
hdfs dfs -put path_to_project/lab1_133/input
yarn jar path_to_project/lab1_133/target/lab1-1.0-SNAPSHOT-jar-with-dependencies.jar input output snappy
(В случае, если третьим аргументом указан snappy, то результирующим файлом будет sequence file со сжатием snappy)

После выполнения программы будут отображены значения счетчиков битых логов(невалидное значение severity, неверное число полей в сообщении лога).
Для просмотра результирующего файла нужно перейти по ссылке http://localhost:50070/explorer.html#/
В том случае, если было использовано snappy сжатие, скачать результирующий файл в текстовом формате можно с помощью команды
hadoop fs -text output/part-r-00000 > {result_filename}

Сценирий использования в том случае, если логов нет:
Отредактировать файл  hadoop_connection.py в местах где стоит комментарий:

 «#изменить путь к проекту lab1_133»


Запустить скрипт командой python3 hadoop_connection.py, предварительно создав папке input в той же директории, где расположен скрипт.
Скрипт сгенерирует 6 файлов с логами (по 1 миллиону строк в каждом), после чего загрузит их в hdfs. В конце работы программы на экран будут выведены результаты работы счетчиков. Также будут скачаны результирующие файлы  hdfs_out либо hdfs_out_snappy(уже разархивированный).
